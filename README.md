Table of Contents
=================

* [The 4 stages of your portfolio](#the-4-stages-of-your-portfolio)
     * [Stage 1: EDA, Data Visualization and programming basics](#stage-1-eda-data-visualization-and-programming-basics)
          * [Deliverable](#deliverable)
          * [Evaluation metrics](#evaluation-metrics)
     * [Stage 2: Developing a research question and analysis](#stage-2-developing-a-research-question-and-analysis)
          * [Deliverable](#deliverable-1)
          * [Evaluation metrics](#evaluation-metrics-1)
     * [Stage 3: Machine Learning Discovery](#stage-3-machine-learning-discovery)
          * [Deliverable](#deliverable-2)
          * [Evaluation metrics](#evaluation-metrics-2)
     * [Stage 4: The Capstone Project](#stage-4-the-capstone-project)
          * [Deliverable](#deliverable-3)
          * [Obtaining data for your Capstone Project](#obtaining-data-for-your-capstone-project)
          * [Additional Details](#additional-details)

## The 4 stages of your portfolio

Throughout the course you have been encouraged to develop your own unique portfolio that will allow you to showcase your skills to colleagues and future employers.

Developing your personal portfolio, your interests and skill set follows 4 stages. Each stage:

1. Builds on the skills gained in the previous stages, and
2. Becomes progressively more difficult and idividualized.

The 4 stages are:

### Stage 1: EDA, Data Visualization and programming basics

Stage 1 occured with the Learning R and Learning Python modules, where you were tasked with working on a simple data set:

- Chicken Weights
- Diamonds
- Optional: Irrigation
- Bonus: Meditation Dataset (In either R OR Python)

The goal here is to showcase your technical skill (GitHub, R, Python, Command Line) and not your nascent analytical skills.

Thus, the data sets used here are very small, clean, easy-to-work-with and well-described.

#### Deliverable

A GitHub Repository titled `DS_EDA_example` containing:

1. Either `Rmarkdown` or `ipynb` documents (output to HTML!)
2. An explanatory `readme.md` file for the repo.

#### Due

End of week 8 (19 Nov 2020)

#### Evaluation metrics

Minimum:
- Does the GitHub repo exist?
- Is the `readme.md` informative?
- Is there at least one R or Python example file viewable in HTML?
- Were the assigned data sets used?
- Were the commands used appropriate and thorough for an EDA?
- Is there non-code commentary?
- Is the code commented (using `#`)?
- Are there apprporiate and useful data visualizations?

Bonus:
- Use of new data sets. 
- Improvement of plot formatting.
- Use of useful plot types discussed in class or the learning material.
- Files in both R and Python.

### Stage 2: Developing a research question and analysis 

Stage 2 also occured in the Learning R and Learning Python modules, where you were tasked with exploring a data set from Kaggle or Tidy Tuesday. These data sets are generally larger than what we used in the first stage. You were asked to revisit this project and translate R into Python. 

The goal here is to showcase your understanding of a reserach problem that a specific dataset can address. 

These data sets are generally very well described, which is a blessing and a curse. You have plenty of resources to review and learn from, but at the same time you need to try and produce something unique. Your analysis should go beyond basic EDA and Data Visualization and try to address specific questions that the producer/holder of this data set would want to have answered.

#### Deliverable

A GitHub repository titled `DS_Research_*`, where `*` is the name of your dataset, e.g. `DS_Research_Indian`. This should contain:

1. An `Rmarkdown` **and** `ipynb` documents (output to HTML!) using at least one data set obtained from Kaggle or Tidy Tuesday.
2. An explanatory `readme.md` file for the repo.

#### Due

End of week 8 (19 Nov 2020)

#### Evaluation metrics

Minimum:
- Does the GitHub repo exist?
- Is the `readme.md` informative?
- Is there at least one R and one Python example file viewabel in HTML?
- Is the source of the data set clear?
- Is there a clear research question that this data set will be used to address?
- Has an analysis been conducted that answers the proposed research question?
- Were the commands used appropriate?
- Is there non-code commentary?
- Is the code commented (using `#`)?
- Are there appropriate and useful data visualizations?

Bonus:
- Creativity in the research question.
- Improvement of plot formatting.
- Use of useful plot types discussed in class or the learning material. 
- Application of appropriate statistical techniques.

### Stage 3: Machine Learning Discovery

Stage 3 occured in the Hands-on Machine Learning module. Throughout the three-week module you have been asked to apply your new knowledge in machine learning in two ways. First, the exercises ask you to work on provided  and well-described data sets. Second, and more importantly, you were tasked with seeking out a new data set to work on in more detail, applying specific machine learning methods where appropriate. 

These data sets are in general less popular, and thus more interesting in helping you to build your portfolio. Links to some resources can be found in the exercises in the Hand-on Machine Learning module.

The goal here is to showcase your comprehension of various machine learning methods, while at the same time further developing your data science skills. You should have executed a Machine Learning workflow in R and Python for this section. 

#### Deliverable

A GitHub repository titled `DS_ML_*`, where `*` is the name of your dataset, e.g. `DS_ML_energy`. This should contain:

1. `Rmarkdown` **and** `ipynb` documents (output to HTML!) where you explore either classification of regression using a variety of methods discuss in class.
2. An explanatory `readme.md` file for the repo.

#### Due

End of week 9 (26 Nov 2020)

#### Evaluation metrics

Minimum:
- Does the GitHub repo exist?
- Is the `readme.md` informative?
- Is there at least one R or Python example file viewable in HTML?
- Is the source of the data set clear?
- Is there a clear classification or regression research question that this data set will be used to address?
- Has an analysis been conducted that answers the proposed research question?
- Have a varity of differnt tools been implemented to answer the research question?
- Are the commands used appropriate?
- Are appropriate feature engineering used?
- Is there sufficient exploration of the data set provided?
- Is there non-code commentary?
- Is the code commented (using `#`)?
- Are there appropriate and useful data visualizations?

Bonus:
- Conclusion as to which algorithim performed best
- Discussion as to strengths and weaknesses of each method as it applies to its specific implementation and/or this data set.
- Creativity in the research question and data set.
- Improvement of plot formatting.
- Use of useful plot types discussed in class or the learning material. 
- Application of ML methods beyond what is discussed in class.

### Stage 4: The Capstone Project

Stage 4 is the Capstone Project, the largest and most time-intensive part of your portfolio. In the last two weeks of the course, you will have time to work on and, in the last days, to present this project.

The Capstone Project is a self-guided research project, each student should have their own project. 

In this stage, you may apply all the material covered in the course, but you can also venture beyond. e.g. you may decide to:

- Develop a reproducible analytical workflow for a specific type of data that you feel is not well-serviced by existing packages in R or Python.
- Create an R or Python package that can be distributed to your colleagues that can be used to address a specific set of analytical problems.
- Explore text using Natural Language Processing (NLP). This module is available but will not be part of the core course.
- Develop an interactive web-interface to a specific workflow, for training, exploring or reporting results. A short module is available in R for this.
- Explore a specific algorithim in Data Science that we have not covered in the course by applying it to different data sets and describing e.g. its assumptions, uses, interpretation and limitations.

These are just some ideas -- Data Science is a vast topic, and we are just scratching the surface of the most useful tools in this course. You may decide to go deeper into topics that are not incluced in this course, such as time series forcasting, geospatial data or financial data. 

Please reach out to your Instructor and Teaching Assisstant for more advice!

#### Deliverable

A GitHub repository titled `DS_Capstone_*`, where `*` is the name of your project or focus, e.g. `DS_Capstone_NLP`, or `DS_Capstone_PyPackage`. This should contain:

- Raw scripts used to analyse your data, or
- `Rmarkdown` and/or `ipynb` documents as needed.
- An explanatory `readme.md` file for the repo.
- The slides for your presentation taking place at the end of the course.

#### Due

- Repository and presentation upload lastest Monday 14 Dec 2020 (Week 12)

### Obtaining data for your Capstone Project

We are at the half-way point of the course, so you should begin thinking about what you want to explore for your Capstone Project now.

It can take several weeks to obtain the data or settle on an appropriate topic. If you are currently working and can obtain propietary data from your employeers, this can be incredible beneficial. It will be unique, and hopefully you can actually use the results of your analysis! If you don't have access to propietary data, then ideally, you would work on a data set that has not been well-described. It can be a public data set, but you should put in the effort to work with it in a way that has not already been done. 

## Additional Details

As the course progresses and we encounter recurring issues with working on the Capstone Project, we'll update this repository with tips to help you along.
